{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science Practicce Session 1: Social Sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is Coronavirus Affecting Lives Across the World?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [COVIDiSTRESS global survey](https://osf.io/z39us/) is an international collaborative undertaking for gathering data on human experiences, behaviour and attitudes during the COVID-19 pandemic. The survey focuses on psychological stress, compliance with behavioural guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures. \n",
    "\n",
    "In this notebook we are going to use the results of the COVIDiSTRESS survey conducted in April–May 2020 to investigate the impact of the Coronavirus pandemic on the perceived level of stress by individuals across the world as well as explore other related factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started we need to import the `pandas` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the relevant dataset as a CSV file from this session's [materials](https://education.wdss.io/python-for-data-science/session-one/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is more complex than the one we looked at in the teaching session and so we will need to acquaint ourselves with some more optional arguments of the `read_csv` function. Namely, look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) of the function, to see what the following parameters are for:\n",
    "\n",
    "- `low_memory`\n",
    "- `parse_dates`\n",
    "- `dayfirst`\n",
    "- `index_col`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this knowledge to import the dataset and assign it to the variable `raw_df`. Pay close attention to the following points:\n",
    "\n",
    "- The dataset has a date column `RecordedDate` which uses day first format\n",
    "- Because many columns have lots of missing values, there will likely be mixed type inference (a bad thing) when using low memory mode\n",
    "- The first column of the dataset consists of row numbers which should be read as an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Duration..in.seconds.      RecordedDate UserLanguage  Dem_age  \\\n",
       "1                       180  30/05/2020 23:47          SAR       29   \n",
       "2                      3100  29/05/2020 23:30           UR       20   \n",
       "3                       127  30/05/2020 22:40          SAR       47   \n",
       "4                      1710  29/05/2020 22:47           BG       79   \n",
       "5                      2239  29/05/2020 22:42          SAR       61   \n",
       "...                     ...               ...          ...      ...   \n",
       "65531                   726  03/04/2020 14:35           FI       43   \n",
       "65532                   918  04/04/2020 14:38           FI       31   \n",
       "65533                  2662  03/04/2020 15:07           FI       69   \n",
       "65534                  1309  03/04/2020 14:45          SAR       36   \n",
       "65535                   957  03/04/2020 14:39           FI       46   \n",
       "\n",
       "      Dem_gender                                            Dem_edu  \\\n",
       "1         Female                   College degree, bachelor, master   \n",
       "2           Male                   College degree, bachelor, master   \n",
       "3         Female  Some College, short continuing education or eq...   \n",
       "4           Male                   College degree, bachelor, master   \n",
       "5         Female  Some College, short continuing education or eq...   \n",
       "...          ...                                                ...   \n",
       "65531     Female                   College degree, bachelor, master   \n",
       "65532     Female                   College degree, bachelor, master   \n",
       "65533     Female                   College degree, bachelor, master   \n",
       "65534     Female  Some College, short continuing education or eq...   \n",
       "65535       Male                            Up to 6 years of school   \n",
       "\n",
       "                      Dem_edu_mom      Dem_employment    Country Dem_Expat  \\\n",
       "1      Some College or equivalent        Not employed  Argentina       yes   \n",
       "2                            None             Student   Pakistan       yes   \n",
       "3      Some College or equivalent       Self-employed  Argentina        no   \n",
       "4                  College degree        Not employed   Bulgaria        no   \n",
       "5        Up to 12 years of school             Retired  Argentina        no   \n",
       "...                           ...                 ...        ...       ...   \n",
       "65531              College degree  Full time employed    Finland        no   \n",
       "65532    Up to 12 years of school  Full time employed    Finland        no   \n",
       "65533     Up to 9 years of school             Retired    Finland        no   \n",
       "65534  Some College or equivalent  Full time employed  Argentina        no   \n",
       "65535                         NaN        Not employed    Finland        no   \n",
       "\n",
       "       ...                                         Final_open PSS10_avg  \\\n",
       "1      ...                                                NaN  2.900000   \n",
       "2      ...                                                NaN  2.200000   \n",
       "3      ...                                                NaN       NaN   \n",
       "4      ...                                                NaN  3.600000   \n",
       "5      ...                        Informaciones no confiables  2.714286   \n",
       "...    ...                                                ...       ...   \n",
       "65531  ...  Lemmikkini menehtyminen vuosi sitten lis‰‰ yks...  2.800000   \n",
       "65532  ...                                                NaN  2.800000   \n",
       "65533  ...                                                NaN  2.100000   \n",
       "65534  ...                                                NaN  2.000000   \n",
       "65535  ...                            Oma terveys on pett‰nyt  3.500000   \n",
       "\n",
       "       SLON3_avg       neu       ext       ope       agr       con SPS_avg  \\\n",
       "1       3.000000       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "2       2.333333  2.000000  5.000000  5.333333  5.000000  5.000000     5.0   \n",
       "3            NaN       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "4       4.000000  4.000000  4.666667  4.000000  5.000000  5.000000     3.9   \n",
       "5       1.000000  3.666667  4.666667  5.333333  5.000000  4.666667     5.0   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "65531   4.666667  2.666667  4.333333  5.333333  4.666667  3.333333     4.4   \n",
       "65532   3.666667  3.666667  5.333333  5.000000  4.666667  3.666667     4.9   \n",
       "65533   2.000000  3.666667  5.000000  4.666667  5.333333  4.666667     5.4   \n",
       "65534   2.333333  4.666667  2.666667  3.666667  4.666667  4.666667     4.4   \n",
       "65535   3.333333  2.333333  4.666667  5.000000  5.333333  3.666667     4.1   \n",
       "\n",
       "      Scale_UCLA_TRI_avg  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "5                    NaN  \n",
       "...                  ...  \n",
       "65531                NaN  \n",
       "65532                NaN  \n",
       "65533                NaN  \n",
       "65534                NaN  \n",
       "65535                NaN  \n",
       "\n",
       "[65535 rows x 152 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Duration..in.seconds.</th>\n      <th>RecordedDate</th>\n      <th>UserLanguage</th>\n      <th>Dem_age</th>\n      <th>Dem_gender</th>\n      <th>Dem_edu</th>\n      <th>Dem_edu_mom</th>\n      <th>Dem_employment</th>\n      <th>Country</th>\n      <th>Dem_Expat</th>\n      <th>...</th>\n      <th>Final_open</th>\n      <th>PSS10_avg</th>\n      <th>SLON3_avg</th>\n      <th>neu</th>\n      <th>ext</th>\n      <th>ope</th>\n      <th>agr</th>\n      <th>con</th>\n      <th>SPS_avg</th>\n      <th>Scale_UCLA_TRI_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>180</td>\n      <td>30/05/2020 23:47</td>\n      <td>SAR</td>\n      <td>29</td>\n      <td>Female</td>\n      <td>College degree, bachelor, master</td>\n      <td>Some College or equivalent</td>\n      <td>Not employed</td>\n      <td>Argentina</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.900000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3100</td>\n      <td>29/05/2020 23:30</td>\n      <td>UR</td>\n      <td>20</td>\n      <td>Male</td>\n      <td>College degree, bachelor, master</td>\n      <td>None</td>\n      <td>Student</td>\n      <td>Pakistan</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.200000</td>\n      <td>2.333333</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>5.333333</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>127</td>\n      <td>30/05/2020 22:40</td>\n      <td>SAR</td>\n      <td>47</td>\n      <td>Female</td>\n      <td>Some College, short continuing education or eq...</td>\n      <td>Some College or equivalent</td>\n      <td>Self-employed</td>\n      <td>Argentina</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1710</td>\n      <td>29/05/2020 22:47</td>\n      <td>BG</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>College degree, bachelor, master</td>\n      <td>College degree</td>\n      <td>Not employed</td>\n      <td>Bulgaria</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>3.600000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.666667</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>3.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2239</td>\n      <td>29/05/2020 22:42</td>\n      <td>SAR</td>\n      <td>61</td>\n      <td>Female</td>\n      <td>Some College, short continuing education or eq...</td>\n      <td>Up to 12 years of school</td>\n      <td>Retired</td>\n      <td>Argentina</td>\n      <td>no</td>\n      <td>...</td>\n      <td>Informaciones no confiables</td>\n      <td>2.714286</td>\n      <td>1.000000</td>\n      <td>3.666667</td>\n      <td>4.666667</td>\n      <td>5.333333</td>\n      <td>5.000000</td>\n      <td>4.666667</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65531</th>\n      <td>726</td>\n      <td>03/04/2020 14:35</td>\n      <td>FI</td>\n      <td>43</td>\n      <td>Female</td>\n      <td>College degree, bachelor, master</td>\n      <td>College degree</td>\n      <td>Full time employed</td>\n      <td>Finland</td>\n      <td>no</td>\n      <td>...</td>\n      <td>Lemmikkini menehtyminen vuosi sitten lis‰‰ yks...</td>\n      <td>2.800000</td>\n      <td>4.666667</td>\n      <td>2.666667</td>\n      <td>4.333333</td>\n      <td>5.333333</td>\n      <td>4.666667</td>\n      <td>3.333333</td>\n      <td>4.4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>65532</th>\n      <td>918</td>\n      <td>04/04/2020 14:38</td>\n      <td>FI</td>\n      <td>31</td>\n      <td>Female</td>\n      <td>College degree, bachelor, master</td>\n      <td>Up to 12 years of school</td>\n      <td>Full time employed</td>\n      <td>Finland</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.800000</td>\n      <td>3.666667</td>\n      <td>3.666667</td>\n      <td>5.333333</td>\n      <td>5.000000</td>\n      <td>4.666667</td>\n      <td>3.666667</td>\n      <td>4.9</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>65533</th>\n      <td>2662</td>\n      <td>03/04/2020 15:07</td>\n      <td>FI</td>\n      <td>69</td>\n      <td>Female</td>\n      <td>College degree, bachelor, master</td>\n      <td>Up to 9 years of school</td>\n      <td>Retired</td>\n      <td>Finland</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.100000</td>\n      <td>2.000000</td>\n      <td>3.666667</td>\n      <td>5.000000</td>\n      <td>4.666667</td>\n      <td>5.333333</td>\n      <td>4.666667</td>\n      <td>5.4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>65534</th>\n      <td>1309</td>\n      <td>03/04/2020 14:45</td>\n      <td>SAR</td>\n      <td>36</td>\n      <td>Female</td>\n      <td>Some College, short continuing education or eq...</td>\n      <td>Some College or equivalent</td>\n      <td>Full time employed</td>\n      <td>Argentina</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>2.333333</td>\n      <td>4.666667</td>\n      <td>2.666667</td>\n      <td>3.666667</td>\n      <td>4.666667</td>\n      <td>4.666667</td>\n      <td>4.4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>65535</th>\n      <td>957</td>\n      <td>03/04/2020 14:39</td>\n      <td>FI</td>\n      <td>46</td>\n      <td>Male</td>\n      <td>Up to 6 years of school</td>\n      <td>NaN</td>\n      <td>Not employed</td>\n      <td>Finland</td>\n      <td>no</td>\n      <td>...</td>\n      <td>Oma terveys on pett‰nyt</td>\n      <td>3.500000</td>\n      <td>3.333333</td>\n      <td>2.333333</td>\n      <td>4.666667</td>\n      <td>5.000000</td>\n      <td>5.333333</td>\n      <td>3.666667</td>\n      <td>4.1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>65535 rows × 152 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "raw_df = pd.read_csv('data/covidstress.csv',low_memory = False,parse_dates=[1],dayfirst = True,index_col=0)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Bonus**\n",
    ">\n",
    "> Suppose we didn't trust the index column of the original dataset. How could we use the default index provide by `pandas` instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the dataset by doing the following:\n",
    "- Print the first 3 rows of the dataset\n",
    "- Print the dimensions of the dataset\n",
    "- Print numerical summaries of the columns\n",
    "- Print the data types of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Duration..in.seconds.      RecordedDate UserLanguage  Dem_age Dem_gender  \\\n",
       "1                   180  30/05/2020 23:47          SAR       29     Female   \n",
       "2                  3100  29/05/2020 23:30           UR       20       Male   \n",
       "3                   127  30/05/2020 22:40          SAR       47     Female   \n",
       "\n",
       "                                             Dem_edu  \\\n",
       "1                   College degree, bachelor, master   \n",
       "2                   College degree, bachelor, master   \n",
       "3  Some College, short continuing education or eq...   \n",
       "\n",
       "                  Dem_edu_mom Dem_employment    Country Dem_Expat  ...  \\\n",
       "1  Some College or equivalent   Not employed  Argentina       yes  ...   \n",
       "2                        None        Student   Pakistan       yes  ...   \n",
       "3  Some College or equivalent  Self-employed  Argentina        no  ...   \n",
       "\n",
       "  Final_open PSS10_avg  SLON3_avg  neu  ext       ope  agr  con SPS_avg  \\\n",
       "1        NaN       2.9   3.000000  NaN  NaN       NaN  NaN  NaN     NaN   \n",
       "2        NaN       2.2   2.333333  2.0  5.0  5.333333  5.0  5.0     5.0   \n",
       "3        NaN       NaN        NaN  NaN  NaN       NaN  NaN  NaN     NaN   \n",
       "\n",
       "  Scale_UCLA_TRI_avg  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "\n",
       "[3 rows x 152 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Duration..in.seconds.</th>\n      <th>RecordedDate</th>\n      <th>UserLanguage</th>\n      <th>Dem_age</th>\n      <th>Dem_gender</th>\n      <th>Dem_edu</th>\n      <th>Dem_edu_mom</th>\n      <th>Dem_employment</th>\n      <th>Country</th>\n      <th>Dem_Expat</th>\n      <th>...</th>\n      <th>Final_open</th>\n      <th>PSS10_avg</th>\n      <th>SLON3_avg</th>\n      <th>neu</th>\n      <th>ext</th>\n      <th>ope</th>\n      <th>agr</th>\n      <th>con</th>\n      <th>SPS_avg</th>\n      <th>Scale_UCLA_TRI_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>180</td>\n      <td>30/05/2020 23:47</td>\n      <td>SAR</td>\n      <td>29</td>\n      <td>Female</td>\n      <td>College degree, bachelor, master</td>\n      <td>Some College or equivalent</td>\n      <td>Not employed</td>\n      <td>Argentina</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.9</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3100</td>\n      <td>29/05/2020 23:30</td>\n      <td>UR</td>\n      <td>20</td>\n      <td>Male</td>\n      <td>College degree, bachelor, master</td>\n      <td>None</td>\n      <td>Student</td>\n      <td>Pakistan</td>\n      <td>yes</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2.2</td>\n      <td>2.333333</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.333333</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>127</td>\n      <td>30/05/2020 22:40</td>\n      <td>SAR</td>\n      <td>47</td>\n      <td>Female</td>\n      <td>Some College, short continuing education or eq...</td>\n      <td>Some College or equivalent</td>\n      <td>Self-employed</td>\n      <td>Argentina</td>\n      <td>no</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 152 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# First 3 rows\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(65535, 152)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "# Dimensions of the dataset\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Dem_age  Dem_dependents  Dem_isolation_adults  Dem_isolation_kids  \\\n",
       "count  65535.000000    63317.000000          53379.000000        52463.000000   \n",
       "mean      40.741375        0.933146              1.533937            0.484513   \n",
       "std       14.322085        1.805861              3.231931            1.275804   \n",
       "min       18.000000        0.000000              0.000000            0.000000   \n",
       "25%       29.000000        0.000000              1.000000            0.000000   \n",
       "50%       40.000000        0.000000              1.000000            0.000000   \n",
       "75%       51.000000        2.000000              2.000000            1.000000   \n",
       "max      110.000000      110.000000            110.000000          110.000000   \n",
       "\n",
       "       Scale_PSS10_UCLA_1  Scale_PSS10_UCLA_2  Scale_PSS10_UCLA_3  \\\n",
       "count        60336.000000        60312.000000        60344.000000   \n",
       "mean             2.556782            2.663450            3.078019   \n",
       "std              1.094821            1.104996            1.112253   \n",
       "min              1.000000            1.000000            1.000000   \n",
       "25%              2.000000            2.000000            2.000000   \n",
       "50%              3.000000            3.000000            3.000000   \n",
       "75%              3.000000            3.000000            4.000000   \n",
       "max              5.000000            5.000000            5.000000   \n",
       "\n",
       "       Scale_PSS10_UCLA_4  Scale_PSS10_UCLA_5  Scale_PSS10_UCLA_6  ...  \\\n",
       "count        60274.000000        60253.000000        60347.000000  ...   \n",
       "mean             3.683612            3.158266            2.683845  ...   \n",
       "std              1.049348            0.968456            1.118127  ...   \n",
       "min              1.000000            1.000000            1.000000  ...   \n",
       "25%              3.000000            3.000000            2.000000  ...   \n",
       "50%              4.000000            3.000000            3.000000  ...   \n",
       "75%              4.000000            4.000000            3.000000  ...   \n",
       "max              5.000000            5.000000            5.000000  ...   \n",
       "\n",
       "       Expl_media_6     PSS10_avg     SLON3_avg           neu           ext  \\\n",
       "count   48753.00000  60811.000000  60673.000000  56884.000000  56858.000000   \n",
       "mean        3.31034      2.628514      2.581236      3.316275      3.999156   \n",
       "std         1.37873      0.735439      0.990043      1.050524      1.116921   \n",
       "min         1.00000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%         2.00000      2.100000      2.000000      2.666667      3.333333   \n",
       "50%         3.00000      2.600000      2.666667      3.333333      4.000000   \n",
       "75%         4.00000      3.100000      3.333333      4.000000      5.000000   \n",
       "max         6.00000      5.000000      5.000000      6.000000      6.000000   \n",
       "\n",
       "                ope           agr           con       SPS_avg  \\\n",
       "count  56856.000000  56869.000000  56865.000000  49669.000000   \n",
       "mean       4.478871      4.439443      4.380509      4.849583   \n",
       "std        0.947898      0.832629      0.890780      0.907215   \n",
       "min        1.000000      1.000000      1.000000      1.000000   \n",
       "25%        4.000000      4.000000      3.666667      4.400000   \n",
       "50%        4.666667      4.666667      4.333333      5.000000   \n",
       "75%        5.000000      5.000000      5.000000      5.500000   \n",
       "max        6.000000      6.000000      6.000000      6.000000   \n",
       "\n",
       "       Scale_UCLA_TRI_avg  \n",
       "count           51.000000  \n",
       "mean             1.818627  \n",
       "std              0.968060  \n",
       "min              0.000000  \n",
       "25%              1.000000  \n",
       "50%              1.750000  \n",
       "75%              2.500000  \n",
       "max              4.000000  \n",
       "\n",
       "[8 rows x 126 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dem_age</th>\n      <th>Dem_dependents</th>\n      <th>Dem_isolation_adults</th>\n      <th>Dem_isolation_kids</th>\n      <th>Scale_PSS10_UCLA_1</th>\n      <th>Scale_PSS10_UCLA_2</th>\n      <th>Scale_PSS10_UCLA_3</th>\n      <th>Scale_PSS10_UCLA_4</th>\n      <th>Scale_PSS10_UCLA_5</th>\n      <th>Scale_PSS10_UCLA_6</th>\n      <th>...</th>\n      <th>Expl_media_6</th>\n      <th>PSS10_avg</th>\n      <th>SLON3_avg</th>\n      <th>neu</th>\n      <th>ext</th>\n      <th>ope</th>\n      <th>agr</th>\n      <th>con</th>\n      <th>SPS_avg</th>\n      <th>Scale_UCLA_TRI_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>65535.000000</td>\n      <td>63317.000000</td>\n      <td>53379.000000</td>\n      <td>52463.000000</td>\n      <td>60336.000000</td>\n      <td>60312.000000</td>\n      <td>60344.000000</td>\n      <td>60274.000000</td>\n      <td>60253.000000</td>\n      <td>60347.000000</td>\n      <td>...</td>\n      <td>48753.00000</td>\n      <td>60811.000000</td>\n      <td>60673.000000</td>\n      <td>56884.000000</td>\n      <td>56858.000000</td>\n      <td>56856.000000</td>\n      <td>56869.000000</td>\n      <td>56865.000000</td>\n      <td>49669.000000</td>\n      <td>51.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>40.741375</td>\n      <td>0.933146</td>\n      <td>1.533937</td>\n      <td>0.484513</td>\n      <td>2.556782</td>\n      <td>2.663450</td>\n      <td>3.078019</td>\n      <td>3.683612</td>\n      <td>3.158266</td>\n      <td>2.683845</td>\n      <td>...</td>\n      <td>3.31034</td>\n      <td>2.628514</td>\n      <td>2.581236</td>\n      <td>3.316275</td>\n      <td>3.999156</td>\n      <td>4.478871</td>\n      <td>4.439443</td>\n      <td>4.380509</td>\n      <td>4.849583</td>\n      <td>1.818627</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.322085</td>\n      <td>1.805861</td>\n      <td>3.231931</td>\n      <td>1.275804</td>\n      <td>1.094821</td>\n      <td>1.104996</td>\n      <td>1.112253</td>\n      <td>1.049348</td>\n      <td>0.968456</td>\n      <td>1.118127</td>\n      <td>...</td>\n      <td>1.37873</td>\n      <td>0.735439</td>\n      <td>0.990043</td>\n      <td>1.050524</td>\n      <td>1.116921</td>\n      <td>0.947898</td>\n      <td>0.832629</td>\n      <td>0.890780</td>\n      <td>0.907215</td>\n      <td>0.968060</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>2.00000</td>\n      <td>2.100000</td>\n      <td>2.000000</td>\n      <td>2.666667</td>\n      <td>3.333333</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.666667</td>\n      <td>4.400000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>3.00000</td>\n      <td>2.600000</td>\n      <td>2.666667</td>\n      <td>3.333333</td>\n      <td>4.000000</td>\n      <td>4.666667</td>\n      <td>4.666667</td>\n      <td>4.333333</td>\n      <td>5.000000</td>\n      <td>1.750000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>51.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>4.00000</td>\n      <td>3.100000</td>\n      <td>3.333333</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.500000</td>\n      <td>2.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>110.000000</td>\n      <td>110.000000</td>\n      <td>110.000000</td>\n      <td>110.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>...</td>\n      <td>6.00000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>4.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 126 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# Numerical summaries of the columns\n",
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Bonus**\n",
    ">\n",
    "> When printing the above, we only get to see 10 columns in total. For printing out full datasets and series, checkout the [option context](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.option_context.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Duration..in.seconds.     object\nRecordedDate              object\nUserLanguage              object\nDem_age                    int64\nDem_gender                object\nDem_edu                   object\nDem_edu_mom               object\nDem_employment            object\nCountry                   object\nDem_Expat                 object\nDem_state                 object\nDem_maritalstatus         object\nDem_dependents           float64\nDem_riskgroup             object\nDem_islolation            object\nDem_isolation_adults     float64\nDem_isolation_kids       float64\nAD_gain                   object\nAD_loss                   object\nAD_check                  object\nScale_PSS10_UCLA_1       float64\nScale_PSS10_UCLA_2       float64\nScale_PSS10_UCLA_3       float64\nScale_PSS10_UCLA_4       float64\nScale_PSS10_UCLA_5       float64\nScale_PSS10_UCLA_6       float64\nScale_PSS10_UCLA_7       float64\nScale_PSS10_UCLA_8       float64\nScale_PSS10_UCLA_9       float64\nScale_PSS10_UCLA_10      float64\nScale_SLON_1             float64\nScale_SLON_2             float64\nScale_SLON_3             float64\nOECD_people_1            float64\nOECD_people_2            float64\nOECD_insititutions_1     float64\nOECD_insititutions_2     float64\nOECD_insititutions_3     float64\nOECD_insititutions_4     float64\nOECD_insititutions_5     float64\nOECD_insititutions_6     float64\nCorona_concerns_1        float64\nCorona_concerns_2        float64\nCorona_concerns_3        float64\nCorona_concerns_4        float64\nCorona_concerns_5        float64\nTrust_countrymeasure     float64\nCompliance_1             float64\nCompliance_2             float64\nCompliance_3             float64\nCompliance_4             float64\nCompliance_5             float64\nCompliance_6             float64\nborn_92                   object\nexperience_war            object\nexperience_war_TXT        object\nwar_injury                object\nloss_during_war           object\ntime_spent_in_war         object\ntime_spent_in_war_TXT     object\nScale_UCLA_TRI_1         float64\nScale_UCLA_TRI_2         float64\nScale_UCLA_TRI_3         float64\nScale_UCLA_TRI_4         float64\nPS_PTSD_1                float64\nPS_PTSD_2                float64\nPS_PTSD_3                float64\nPS_PTSD_4                float64\nPS_PTSD_5                float64\nBFF_15_1                 float64\nBFF_15_2                 float64\nBFF_15_3                 float64\nBFF_15_4                 float64\nBFF_15_5                 float64\nBFF_15_6                 float64\nBFF_15_7                 float64\nBFF_15_8                 float64\nBFF_15_9                 float64\nBFF_15_10                float64\nBFF_15_11                float64\nBFF_15_12                float64\nBFF_15_13                float64\nBFF_15_14                float64\nBFF_15_15                float64\nExpl_Distress_1          float64\nExpl_Distress_2          float64\nExpl_Distress_3          float64\nExpl_Distress_4          float64\nExpl_Distress_5          float64\nExpl_Distress_6          float64\nExpl_Distress_7          float64\nExpl_Distress_8          float64\nExpl_Distress_9          float64\nExpl_Distress_10         float64\nExpl_Distress_11         float64\nExpl_Distress_12         float64\nExpl_Distress_13         float64\nExpl_Distress_14         float64\nExpl_Distress_15         float64\nExpl_Distress_16         float64\nExpl_Distress_17         float64\nExpl_Distress_18         float64\nExpl_Distress_19         float64\nExpl_Distress_20         float64\nExpl_Distress_21         float64\nExpl_Distress_22         float64\nExpl_Distress_23         float64\nExpl_Distress_24         float64\nExpl_Distress_txt         object\nSPS_1                    float64\nSPS_2                    float64\nSPS_3                    float64\nSPS_4                    float64\nSPS_5                    float64\nSPS_6                    float64\nSPS_7                    float64\nSPS_8                    float64\nSPS_9                    float64\nSPS_10                   float64\nExpl_Coping_1            float64\nExpl_Coping_2            float64\nExpl_Coping_3            float64\nExpl_Coping_4            float64\nExpl_Coping_5            float64\nExpl_Coping_6            float64\nExpl_Coping_7            float64\nExpl_Coping_8            float64\nExpl_Coping_9            float64\nExpl_Coping_10           float64\nExpl_Coping_11           float64\nExpl_Coping_12           float64\nExpl_Coping_13           float64\nExpl_Coping_14           float64\nExpl_Coping_15           float64\nExpl_Coping_16           float64\nExpl_coping_txt           object\nExpl_media_1             float64\nExpl_media_2             float64\nExpl_media_3             float64\nExpl_media_4             float64\nExpl_media_5             float64\nExpl_media_6             float64\nFinal_open                object\nPSS10_avg                float64\nSLON3_avg                float64\nneu                      float64\next                      float64\nope                      float64\nagr                      float64\ncon                      float64\nSPS_avg                  float64\nScale_UCLA_TRI_avg       float64\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data types of columns\n",
    "with pd.option_context(\"display.max_rows\", raw_df.shape[1]):          #Here I have printed all of the column types \n",
    "    print(raw_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 152 columns in the dataset, many of which we won't need in our analysis. Instead, we want to focus on the following variables.\n",
    "\n",
    "| description | variable name | measurement |\n",
    "| --- | --- | --- |\n",
    "| date of record | `RecordedDate` | date \"DD/MM/YYYY hh:mm\"\n",
    "| age | `Dem_age` | age in years\n",
    "| gender | `Dem_gender` | Male/Female\n",
    "| country | `Country` | country name\n",
    "| employment status| `Dem_employment` | type of employment\n",
    "| perceived stress for the past week | `Scale_PSS10_UCLA_1` to `Scale_PSS10_UCLA_10` | 1=never, 5=very often; 10 items\n",
    "| trust in institutions | `OECD_insititutions_1` (government), `OECD_insititutions_4` (health system) | 0=not at all, 10=completely\n",
    "| trust in country's preventive measures | `Trust_countrymeasure` | 0=too little, 5= appropriate, 11=too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stress was meassured in 10 different categories. Create a list, `stress_columns` of column names `Scale_PSS10_UCLA_X`, where `X` ranges from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Scale_PSS10_UCLA_1',\n",
       " 'Scale_PSS10_UCLA_2',\n",
       " 'Scale_PSS10_UCLA_3',\n",
       " 'Scale_PSS10_UCLA_4',\n",
       " 'Scale_PSS10_UCLA_5',\n",
       " 'Scale_PSS10_UCLA_6',\n",
       " 'Scale_PSS10_UCLA_7',\n",
       " 'Scale_PSS10_UCLA_8',\n",
       " 'Scale_PSS10_UCLA_9',\n",
       " 'Scale_PSS10_UCLA_10']"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "stress_columns = ['Scale_PSS10_UCLA_'+ str(x) for x in range(1,11)]\n",
    "stress_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then combine these with the other column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['RecordedDate',\n",
       " 'Dem_age',\n",
       " 'Dem_gender',\n",
       " 'Country',\n",
       " 'Dem_employment',\n",
       " 'OECD_insititutions_1',\n",
       " 'OECD_insititutions_4',\n",
       " 'Trust_countrymeasure',\n",
       " 'Scale_PSS10_UCLA_1',\n",
       " 'Scale_PSS10_UCLA_2',\n",
       " 'Scale_PSS10_UCLA_3',\n",
       " 'Scale_PSS10_UCLA_4',\n",
       " 'Scale_PSS10_UCLA_5',\n",
       " 'Scale_PSS10_UCLA_6',\n",
       " 'Scale_PSS10_UCLA_7',\n",
       " 'Scale_PSS10_UCLA_8',\n",
       " 'Scale_PSS10_UCLA_9',\n",
       " 'Scale_PSS10_UCLA_10']"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "columns = [\n",
    "    'RecordedDate', 'Dem_age', 'Dem_gender', 'Country', 'Dem_employment',\n",
    "    'OECD_insititutions_1', 'OECD_insititutions_4', 'Trust_countrymeasure'\n",
    "] + stress_columns\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a subset of this dataset, `covid_stress`, containing only columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           RecordedDate  Dem_age Dem_gender    Country      Dem_employment  \\\n",
       "1      30/05/2020 23:47       29     Female  Argentina        Not employed   \n",
       "2      29/05/2020 23:30       20       Male   Pakistan             Student   \n",
       "3      30/05/2020 22:40       47     Female  Argentina       Self-employed   \n",
       "4      29/05/2020 22:47       79       Male   Bulgaria        Not employed   \n",
       "5      29/05/2020 22:42       61     Female  Argentina             Retired   \n",
       "...                 ...      ...        ...        ...                 ...   \n",
       "65531  03/04/2020 14:35       43     Female    Finland  Full time employed   \n",
       "65532  04/04/2020 14:38       31     Female    Finland  Full time employed   \n",
       "65533  03/04/2020 15:07       69     Female    Finland             Retired   \n",
       "65534  03/04/2020 14:45       36     Female  Argentina  Full time employed   \n",
       "65535  03/04/2020 14:39       46       Male    Finland        Not employed   \n",
       "\n",
       "       OECD_insititutions_1  OECD_insititutions_4  Trust_countrymeasure  \\\n",
       "1                       NaN                   NaN                   NaN   \n",
       "2                       5.0                   2.0                   5.0   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       0.0                   4.0                   5.0   \n",
       "5                       9.0                   9.0                   5.0   \n",
       "...                     ...                   ...                   ...   \n",
       "65531                   9.0                   9.0                   5.0   \n",
       "65532                   7.0                   8.0                   5.0   \n",
       "65533                   8.0                   9.0                   5.0   \n",
       "65534                   5.0                   7.0                   2.0   \n",
       "65535                   8.0                  10.0                   5.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_1  Scale_PSS10_UCLA_2  Scale_PSS10_UCLA_3  \\\n",
       "1                     5.0                 2.0                 5.0   \n",
       "2                     3.0                 3.0                 1.0   \n",
       "3                     NaN                 NaN                 NaN   \n",
       "4                     3.0                 5.0                 3.0   \n",
       "5                     3.0                 3.0                 2.0   \n",
       "...                   ...                 ...                 ...   \n",
       "65531                 2.0                 2.0                 4.0   \n",
       "65532                 3.0                 3.0                 3.0   \n",
       "65533                 2.0                 2.0                 3.0   \n",
       "65534                 2.0                 3.0                 3.0   \n",
       "65535                 3.0                 5.0                 4.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_4  Scale_PSS10_UCLA_5  Scale_PSS10_UCLA_6  \\\n",
       "1                     4.0                 4.0                 1.0   \n",
       "2                     5.0                 2.0                 3.0   \n",
       "3                     NaN                 NaN                 NaN   \n",
       "4                     3.0                 3.0                 5.0   \n",
       "5                     NaN                 3.0                 NaN   \n",
       "...                   ...                 ...                 ...   \n",
       "65531                 3.0                 2.0                 2.0   \n",
       "65532                 4.0                 4.0                 3.0   \n",
       "65533                 4.0                 4.0                 2.0   \n",
       "65534                 5.0                 2.0                 1.0   \n",
       "65535                 3.0                 3.0                 4.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_7  Scale_PSS10_UCLA_8  Scale_PSS10_UCLA_9  \\\n",
       "1                     3.0                 5.0                 3.0   \n",
       "2                     4.0                 4.0                 2.0   \n",
       "3                     NaN                 NaN                 NaN   \n",
       "4                     2.0                 3.0                 3.0   \n",
       "5                     5.0                 2.0                 NaN   \n",
       "...                   ...                 ...                 ...   \n",
       "65531                 3.0                 3.0                 3.0   \n",
       "65532                 3.0                 3.0                 2.0   \n",
       "65533                 4.0                 4.0                 2.0   \n",
       "65534                 5.0                 4.0                 2.0   \n",
       "65535                 3.0                 3.0                 4.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_10  \n",
       "1                      5.0  \n",
       "2                      1.0  \n",
       "3                      NaN  \n",
       "4                      4.0  \n",
       "5                      3.0  \n",
       "...                    ...  \n",
       "65531                  2.0  \n",
       "65532                  4.0  \n",
       "65533                  2.0  \n",
       "65534                  1.0  \n",
       "65535                  3.0  \n",
       "\n",
       "[65535 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordedDate</th>\n      <th>Dem_age</th>\n      <th>Dem_gender</th>\n      <th>Country</th>\n      <th>Dem_employment</th>\n      <th>OECD_insititutions_1</th>\n      <th>OECD_insititutions_4</th>\n      <th>Trust_countrymeasure</th>\n      <th>Scale_PSS10_UCLA_1</th>\n      <th>Scale_PSS10_UCLA_2</th>\n      <th>Scale_PSS10_UCLA_3</th>\n      <th>Scale_PSS10_UCLA_4</th>\n      <th>Scale_PSS10_UCLA_5</th>\n      <th>Scale_PSS10_UCLA_6</th>\n      <th>Scale_PSS10_UCLA_7</th>\n      <th>Scale_PSS10_UCLA_8</th>\n      <th>Scale_PSS10_UCLA_9</th>\n      <th>Scale_PSS10_UCLA_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>30/05/2020 23:47</td>\n      <td>29</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Not employed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29/05/2020 23:30</td>\n      <td>20</td>\n      <td>Male</td>\n      <td>Pakistan</td>\n      <td>Student</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30/05/2020 22:40</td>\n      <td>47</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Self-employed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29/05/2020 22:47</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Bulgaria</td>\n      <td>Not employed</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>29/05/2020 22:42</td>\n      <td>61</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Retired</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65531</th>\n      <td>03/04/2020 14:35</td>\n      <td>43</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>65532</th>\n      <td>04/04/2020 14:38</td>\n      <td>31</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>65533</th>\n      <td>03/04/2020 15:07</td>\n      <td>69</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Retired</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>65534</th>\n      <td>03/04/2020 14:45</td>\n      <td>36</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Full time employed</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>65535</th>\n      <td>03/04/2020 14:39</td>\n      <td>46</td>\n      <td>Male</td>\n      <td>Finland</td>\n      <td>Not employed</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>65535 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "covid_stress = raw_df.loc[:,columns]\n",
    "covid_stress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset is fairly large so we may want to remove it from memory now that we no longer need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear up memory\n",
    "del raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many fields in the dataset have missing/unknown values. We can use `covid_stress.isna()` to return a Boolean dataset where each value is `True` if the original value in that field was missing. Let's investigate where these missing values are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember, `True`/`False` are converted to `1`/`0` respectively when cast to integers. This means we can use the `sum` and `mean` methods on a Boolean dataset or series to count or find proportions of `True`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 154,\n",
       " 345,\n",
       " 659,\n",
       " 8074,\n",
       " 7547,\n",
       " 7304,\n",
       " 5199,\n",
       " 5223,\n",
       " 5191,\n",
       " 5261,\n",
       " 5282,\n",
       " 5188,\n",
       " 5277,\n",
       " 5298,\n",
       " 5163,\n",
       " 5190]"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "# How many missing values are there in each column?\n",
    "\n",
    "[sum(covid_stress.iloc[:,x].isna()) for x in range(0, covid_stress.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "covid_stress.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1706111238269627"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "# What proportion of records (rows) have at least one missing value?\n",
    "miss_per_row = [sum(covid_stress.iloc[x,:].isna()) for x in range(0, covid_stress.shape[0])]\n",
    "sum(i >= 1 for i in miss_per_row)/covid_stress.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have 65535 records in total we can drop all the records with at least one missing value and still have many tens of thousands left. We will learn how to deal with missing values properly in later sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we use the `dropna` method of the dataframe. Search for \"pandas drop missing values\" on the web to find the documentation for this. Save the cleaned dataset as `covid_stress_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_stress_clean = covid_stress.dropna(how = 'any')  # This drop any rows that have any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Bonus**\n",
    ">\n",
    "> Recall from the teaching session that many pandas operations can be done _inplace_. How would we drop rows with missing values in this fashion (check the documentation again if needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a random sample of 10 rows and verify that they have no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           RecordedDate  Dem_age Dem_gender      Country      Dem_employment  \\\n",
       "43037  06/04/2020 16:21       42     Female       Kosovo  Part time employed   \n",
       "33244  08/04/2020 12:44       49     Female      Finland  Full time employed   \n",
       "55522  04/04/2020 23:43       52       Male      Finland  Full time employed   \n",
       "34548  08/04/2020 06:16       23     Female      Finland        Not employed   \n",
       "22273  13/04/2020 12:24       57     Female       Sweden       Self-employed   \n",
       "31087  09/04/2020 05:58       45       Male       Sweden  Full time employed   \n",
       "24595  12/04/2020 12:36       49     Female       Sweden  Full time employed   \n",
       "12981  19/04/2020 05:26       27     Female  Switzerland  Part time employed   \n",
       "4454   12/05/2020 01:53       36       Male        Spain  Full time employed   \n",
       "16424  18/04/2020 02:44       49     Female  Netherlands       Self-employed   \n",
       "\n",
       "       OECD_insititutions_1  OECD_insititutions_4  Trust_countrymeasure  \\\n",
       "43037                   8.0                   7.0                  10.0   \n",
       "33244                   7.0                   6.0                   5.0   \n",
       "55522                   6.0                   9.0                   5.0   \n",
       "34548                   6.0                   9.0                   4.0   \n",
       "22273                  10.0                  10.0                   9.0   \n",
       "31087                   8.0                   7.0                   5.0   \n",
       "24595                   9.0                   9.0                   5.0   \n",
       "12981                   7.0                   6.0                   5.0   \n",
       "4454                    7.0                   6.0                   3.0   \n",
       "16424                   8.0                   9.0                   7.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_1  Scale_PSS10_UCLA_2  Scale_PSS10_UCLA_3  \\\n",
       "43037                 3.0                 4.0                 3.0   \n",
       "33244                 2.0                 2.0                 2.0   \n",
       "55522                 1.0                 1.0                 2.0   \n",
       "34548                 1.0                 4.0                 3.0   \n",
       "22273                 2.0                 3.0                 3.0   \n",
       "31087                 1.0                 5.0                 2.0   \n",
       "24595                 1.0                 5.0                 2.0   \n",
       "12981                 3.0                 3.0                 3.0   \n",
       "4454                  2.0                 2.0                 2.0   \n",
       "16424                 1.0                 2.0                 2.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_4  Scale_PSS10_UCLA_5  Scale_PSS10_UCLA_6  \\\n",
       "43037                 5.0                 3.0                 4.0   \n",
       "33244                 5.0                 4.0                 2.0   \n",
       "55522                 5.0                 5.0                 1.0   \n",
       "34548                 3.0                 3.0                 3.0   \n",
       "22273                 5.0                 2.0                 1.0   \n",
       "31087                 2.0                 3.0                 3.0   \n",
       "24595                 5.0                 4.0                 2.0   \n",
       "12981                 4.0                 4.0                 2.0   \n",
       "4454                  5.0                 2.0                 2.0   \n",
       "16424                 4.0                 4.0                 1.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_7  Scale_PSS10_UCLA_8  Scale_PSS10_UCLA_9  \\\n",
       "43037                 4.0                 3.0                 3.0   \n",
       "33244                 4.0                 5.0                 1.0   \n",
       "55522                 4.0                 5.0                 1.0   \n",
       "34548                 4.0                 4.0                 2.0   \n",
       "22273                 4.0                 2.0                 3.0   \n",
       "31087                 5.0                 4.0                 2.0   \n",
       "24595                 5.0                 5.0                 1.0   \n",
       "12981                 4.0                 4.0                 3.0   \n",
       "4454                  5.0                 4.0                 1.0   \n",
       "16424                 4.0                 4.0                 1.0   \n",
       "\n",
       "       Scale_PSS10_UCLA_10  \n",
       "43037                  2.0  \n",
       "33244                  1.0  \n",
       "55522                  1.0  \n",
       "34548                  2.0  \n",
       "22273                  1.0  \n",
       "31087                  1.0  \n",
       "24595                  1.0  \n",
       "12981                  1.0  \n",
       "4454                   1.0  \n",
       "16424                  2.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordedDate</th>\n      <th>Dem_age</th>\n      <th>Dem_gender</th>\n      <th>Country</th>\n      <th>Dem_employment</th>\n      <th>OECD_insititutions_1</th>\n      <th>OECD_insititutions_4</th>\n      <th>Trust_countrymeasure</th>\n      <th>Scale_PSS10_UCLA_1</th>\n      <th>Scale_PSS10_UCLA_2</th>\n      <th>Scale_PSS10_UCLA_3</th>\n      <th>Scale_PSS10_UCLA_4</th>\n      <th>Scale_PSS10_UCLA_5</th>\n      <th>Scale_PSS10_UCLA_6</th>\n      <th>Scale_PSS10_UCLA_7</th>\n      <th>Scale_PSS10_UCLA_8</th>\n      <th>Scale_PSS10_UCLA_9</th>\n      <th>Scale_PSS10_UCLA_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43037</th>\n      <td>06/04/2020 16:21</td>\n      <td>42</td>\n      <td>Female</td>\n      <td>Kosovo</td>\n      <td>Part time employed</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>33244</th>\n      <td>08/04/2020 12:44</td>\n      <td>49</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>55522</th>\n      <td>04/04/2020 23:43</td>\n      <td>52</td>\n      <td>Male</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>34548</th>\n      <td>08/04/2020 06:16</td>\n      <td>23</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Not employed</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>22273</th>\n      <td>13/04/2020 12:24</td>\n      <td>57</td>\n      <td>Female</td>\n      <td>Sweden</td>\n      <td>Self-employed</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>31087</th>\n      <td>09/04/2020 05:58</td>\n      <td>45</td>\n      <td>Male</td>\n      <td>Sweden</td>\n      <td>Full time employed</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>24595</th>\n      <td>12/04/2020 12:36</td>\n      <td>49</td>\n      <td>Female</td>\n      <td>Sweden</td>\n      <td>Full time employed</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12981</th>\n      <td>19/04/2020 05:26</td>\n      <td>27</td>\n      <td>Female</td>\n      <td>Switzerland</td>\n      <td>Part time employed</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4454</th>\n      <td>12/05/2020 01:53</td>\n      <td>36</td>\n      <td>Male</td>\n      <td>Spain</td>\n      <td>Full time employed</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16424</th>\n      <td>18/04/2020 02:44</td>\n      <td>49</td>\n      <td>Female</td>\n      <td>Netherlands</td>\n      <td>Self-employed</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "# Random sample of cleaned dataset\n",
    "covid_stress_clean.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note, the `covid_stress` dataset isn't too large so we don't need to worry about deleting it. Sometimes it's worth holding onto these things in case we need to go back to them and don't want to rerun cells. How big is the dataset exactly? Have a look at the documentation for the `info` method, which can answer this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 65535 entries, 1 to 65535\nData columns (total 18 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   RecordedDate          65535 non-null  object \n 1   Dem_age               65535 non-null  int64  \n 2   Dem_gender            65381 non-null  object \n 3   Country               65190 non-null  object \n 4   Dem_employment        64876 non-null  object \n 5   OECD_insititutions_1  57461 non-null  float64\n 6   OECD_insititutions_4  57988 non-null  float64\n 7   Trust_countrymeasure  58231 non-null  float64\n 8   Scale_PSS10_UCLA_1    60336 non-null  float64\n 9   Scale_PSS10_UCLA_2    60312 non-null  float64\n 10  Scale_PSS10_UCLA_3    60344 non-null  float64\n 11  Scale_PSS10_UCLA_4    60274 non-null  float64\n 12  Scale_PSS10_UCLA_5    60253 non-null  float64\n 13  Scale_PSS10_UCLA_6    60347 non-null  float64\n 14  Scale_PSS10_UCLA_7    60258 non-null  float64\n 15  Scale_PSS10_UCLA_8    60237 non-null  float64\n 16  Scale_PSS10_UCLA_9    60372 non-null  float64\n 17  Scale_PSS10_UCLA_10   60345 non-null  float64\ndtypes: float64(13), int64(1), object(4)\nmemory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "covid_stress.info()   # Output gives the memory usage at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, we will make a copy of the current dataframe. This will make it easier to return to this point by rerunning this cell if any mistakes are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_stress_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The levels of stress were measured in 10 different categories on a scale from 1=never, 5=very often. We want analyse only aggregated information about the stress level, i.e. the mean of those 10 values. For this, we create a new column `Avg_stress`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['RecordedDate', 'Dem_age', 'Dem_gender', 'Country', 'Dem_employment',\n",
       "       'OECD_insititutions_1', 'OECD_insititutions_4', 'Trust_countrymeasure',\n",
       "       'Scale_PSS10_UCLA_1', 'Scale_PSS10_UCLA_2', 'Scale_PSS10_UCLA_3',\n",
       "       'Scale_PSS10_UCLA_4', 'Scale_PSS10_UCLA_5', 'Scale_PSS10_UCLA_6',\n",
       "       'Scale_PSS10_UCLA_7', 'Scale_PSS10_UCLA_8', 'Scale_PSS10_UCLA_9',\n",
       "       'Scale_PSS10_UCLA_10'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "covid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column by averaging all stress columns\n",
    "covid_df['Avg_stress'] = covid_df[stress_columns].mean(axis = 1)\n",
    "\n",
    "\n",
    "# Drop the now redundant stress columns\n",
    "covid_df = covid_df.drop(stress_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names `OECD_insititutions_1`, `OECD_insititutions_4` are not the most friendly. Let's rename them to something more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           RecordedDate  Dem_age                  Dem_gender    Country  \\\n",
       "2      29/05/2020 23:30       20                        Male   Pakistan   \n",
       "4      29/05/2020 22:47       79                        Male   Bulgaria   \n",
       "6      29/05/2020 21:25       68                        Male      Italy   \n",
       "7      29/05/2020 21:25       29  Other/would rather not say  Argentina   \n",
       "8      29/05/2020 21:25       38                      Female  Argentina   \n",
       "...                 ...      ...                         ...        ...   \n",
       "65531  03/04/2020 14:35       43                      Female    Finland   \n",
       "65532  04/04/2020 14:38       31                      Female    Finland   \n",
       "65533  03/04/2020 15:07       69                      Female    Finland   \n",
       "65534  03/04/2020 14:45       36                      Female  Argentina   \n",
       "65535  03/04/2020 14:39       46                        Male    Finland   \n",
       "\n",
       "           Dem_employment  Trust_gov  Trust_health  Trust_countrymeasure  \\\n",
       "2                 Student        5.0           2.0                   5.0   \n",
       "4            Not employed        0.0           4.0                   5.0   \n",
       "6                 Retired        7.0           8.0                   5.0   \n",
       "7      Part time employed        3.0           4.0                   5.0   \n",
       "8            Not employed        3.0           3.0                   4.0   \n",
       "...                   ...        ...           ...                   ...   \n",
       "65531  Full time employed        9.0           9.0                   5.0   \n",
       "65532  Full time employed        7.0           8.0                   5.0   \n",
       "65533             Retired        8.0           9.0                   5.0   \n",
       "65534  Full time employed        5.0           7.0                   2.0   \n",
       "65535        Not employed        8.0          10.0                   5.0   \n",
       "\n",
       "       Avg_stress  \n",
       "2             2.8  \n",
       "4             3.4  \n",
       "6             2.9  \n",
       "7             2.9  \n",
       "8             3.4  \n",
       "...           ...  \n",
       "65531         2.6  \n",
       "65532         3.2  \n",
       "65533         2.9  \n",
       "65534         2.8  \n",
       "65535         3.5  \n",
       "\n",
       "[54354 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecordedDate</th>\n      <th>Dem_age</th>\n      <th>Dem_gender</th>\n      <th>Country</th>\n      <th>Dem_employment</th>\n      <th>Trust_gov</th>\n      <th>Trust_health</th>\n      <th>Trust_countrymeasure</th>\n      <th>Avg_stress</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>29/05/2020 23:30</td>\n      <td>20</td>\n      <td>Male</td>\n      <td>Pakistan</td>\n      <td>Student</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>2.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29/05/2020 22:47</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Bulgaria</td>\n      <td>Not employed</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>29/05/2020 21:25</td>\n      <td>68</td>\n      <td>Male</td>\n      <td>Italy</td>\n      <td>Retired</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>2.9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>29/05/2020 21:25</td>\n      <td>29</td>\n      <td>Other/would rather not say</td>\n      <td>Argentina</td>\n      <td>Part time employed</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>2.9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>29/05/2020 21:25</td>\n      <td>38</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Not employed</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65531</th>\n      <td>03/04/2020 14:35</td>\n      <td>43</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>2.6</td>\n    </tr>\n    <tr>\n      <th>65532</th>\n      <td>04/04/2020 14:38</td>\n      <td>31</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Full time employed</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>3.2</td>\n    </tr>\n    <tr>\n      <th>65533</th>\n      <td>03/04/2020 15:07</td>\n      <td>69</td>\n      <td>Female</td>\n      <td>Finland</td>\n      <td>Retired</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>2.9</td>\n    </tr>\n    <tr>\n      <th>65534</th>\n      <td>03/04/2020 14:45</td>\n      <td>36</td>\n      <td>Female</td>\n      <td>Argentina</td>\n      <td>Full time employed</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>2.8</td>\n    </tr>\n    <tr>\n      <th>65535</th>\n      <td>03/04/2020 14:39</td>\n      <td>46</td>\n      <td>Male</td>\n      <td>Finland</td>\n      <td>Not employed</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>54354 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "mapper = {\n",
    "    \"OECD_insititutions_1\" : \"Trust_gov\",\n",
    "    \"OECD_insititutions_4\" : \"Trust_health\"\n",
    "}\n",
    "covid_df = covid_df.rename(mapper, axis=1)\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to start answering questions about the dataset. Let's print out the data types of the columns to check that everything is as expected before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RecordedDate             object\n",
       "Dem_age                   int64\n",
       "Dem_gender               object\n",
       "Country                  object\n",
       "Dem_employment           object\n",
       "Trust_gov               float64\n",
       "Trust_health            float64\n",
       "Trust_countrymeasure    float64\n",
       "Avg_stress              float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "covid_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the variable types of each of the column is as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the study was conducted? (i.e. what is the range of dates in the records?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RecordedDate    30/05/2020 20:14\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "# Minimum and maximum dates in dataset\n",
    "covid_df[['RecordedDate']].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RecordedDate    01/05/2020 00:33\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "covid_df[['RecordedDate']].min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of observations are from Finland, Sweden, or Norway? Use `.round()` to print the answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of Finish, Swedish, Norwegian respondents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the dataset sorted by age in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by decreasing age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the median value for age? Print your answer as part of a meaningful sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median age of respondents\n",
    "print(\"The median age of respondents is\", covid_df.Dem_age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Respondents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the gender breakdown of respondents? Use the `value_counts` method to find out (after searching for its documentation of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender breakdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nicer to see percentages rather than absolute counts. There are many ways to do this. Take your pick or write down as many as you can think of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender breakdown as proportions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to divide the respondents in 4 age of equal width, how many respondents would land in each group? (This can also be performed using `value_counts` too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned value counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of the observations have each employment type, excluding students and retirees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment types for non-students/retirees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stress During the COVID-19 Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform grouped summaries using the `groupby` method, documented [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html). These returned a grouped dataframe, which we can apply aggregation methods such as `mean` and `min` to, in which case the aggregation is applied separately to each group. An example is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.groupby('Dem_edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First observation for each gender\n",
    "covid_df.groupby('Dem_gender')['RecordedDate'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the 10 countries with the highest average value of stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much can we trust these values? Are there enough respondents from each of those countries to make an an inference about the level of stress of the entire country? It would be helpful to aggregate both the mean stress level and observation count. We can do this using the `agg` method. Read the documentation for this then use it to recreate the above result with counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suprising? Now let's identify 10 countries with highest average value of stress with at least 200 respondents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df[country_df['Count'] >= 200] \\\n",
    "    .sort_values('Mean_stress', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extend this comparison, we wish to create a dateset `country_fltr` which contains the mean stress, trust in health organisations, government and health measures, and the observation count for all countries with at least 200 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = covid_df.groupby('Country').agg(\n",
    "    Mean_stress=('Avg_stress', 'mean'),\n",
    "    Mean_gov_trust=('Trust_gov', 'mean'),\n",
    "    Mean_health_trust=('Trust_health', 'mean'),\n",
    "    Mean_measures_trust=('Trust_countrymeasure', 'mean'),\n",
    "    Count=('Country', 'count')\n",
    ")\n",
    "\n",
    "country_fltr = country_df[country_df.Count>200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort `country_fltr` by different categories and in ascending/descending order, to explore these 4 measure across the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be interesting to compare the trust in country's health system with the average stress level. One way to do it is to make a scatter plot with the mean trust in health on the x-axis and mean level of stress on the y-axis. (More about plotting in next session, but I couldn't resist making at least one plot in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_fltr.plot(x='Mean_health_trust', y='Mean_stress', kind='scatter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! It seems like there is a negative correlation between these two variables. Can you spot the outlier? Find out which country this datapoint corresponds to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Closer Look at the UK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will draw comparisons between the United Kingdom and the rest of Europe. We have provided an Excel spreadsheet in the [session materials](https://education.wdss.io/python-for-data-science/session-one/) that maps countries to continents, which can be used to aid in this comparison. Start by loading this dataset into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the country mapping spreadsheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas series of all European countries except the United Kingdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this series to create two dataframes, `uk_df` and `euro_df` containing observations from the UK and rest of Europe respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = # ...\n",
    "euro_df = # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the average stress level in the UK above or below average of the rest of Europe? By how much? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What proportion of people in the UK aged between 40 and 60 (inclusive) reported an average stress level above 3? This is a longer question so try to break it up into sensible chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the average stress level for each employment status and gender pair in Europe? (Note: you can use a list of labels when grouping a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wow! What happened there? We've just been introduced to the pandas multi-index, a relatively unique feature of the package which offers incredible power and flexibility. This is considered an advanced feature and so we will not go into any more detail about it but you can read more [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the trust in government tend to increase/decrease or remain stable over the period considered in the report? Compare the mean trust in government in first 3 weeks of April starting from 2020-04-06."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this using base Python `for` loops. Loop through through consecutive pairs of days in the provided date list and calculate the mean trust in government for an subset of the dataset filtered to only have days between the current date in the list and 7 days in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't the most elegant and is certainly not the most efficient. A better solution is below, though it goes to show that pandas and base Python can be used together when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df.groupby(uk_df.RecordedDate.dt.isocalendar().week).mean()['Trust_gov']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Time to Shine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come up with some new questions about this dataset and try to answer them using your newly obtained skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python for Data Science",
   "language": "python",
   "name": "pyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}